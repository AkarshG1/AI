{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "Sanity checks in functions |\n",
    "Regularisation |\n",
    "Prevent underflow/overflow |\n",
    "Refactor code to make more streamlined |\n",
    "Metrics: Precision, Recall, F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_imgs(X):\n",
    "    n_img = np.shape(X)[0]\n",
    "    h = np.shape(X)[1]\n",
    "    w = np.shape(X)[2]\n",
    "    size_arr = h*w\n",
    "    return np.reshape(X,(n_img,size_arr))\n",
    "\n",
    "def one_hot(Y,n_class):\n",
    "    length = np.shape(Y)[1]\n",
    "    O = np.zeros((n_class,length))\n",
    "    for i in range(length):\n",
    "        j = int(Y[0,i])\n",
    "        O[j,i] = 1\n",
    "    return O\n",
    "\n",
    "def inv_one_hot(O):\n",
    "    n_class = np.shape(O)[0]\n",
    "    length = np.shape(O)[1]\n",
    "    Y = np.zeros((1,length))\n",
    "    for i in range(length):\n",
    "        j = np.argmax(O[:,i])\n",
    "        Y[0,i] = j\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean = np.mean(X)\n",
    "    std =  np.std(X)\n",
    "    N_X = (X-mean)/(std)\n",
    "    return N_X\n",
    "\n",
    "def model_accuracy(H,Y):\n",
    "    n = np.shape(H)[1]\n",
    "    err = 0\n",
    "    for i in range(n):\n",
    "        if H[0,i]!=Y[0,i]:\n",
    "            err += 1\n",
    "    accuracy = (1 - err/n)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sigmoid:\n",
    "    def activate(Z):\n",
    "        A = 1/(1+np.exp(-Z))\n",
    "        return A\n",
    "    \n",
    "    def diff(self,Z):\n",
    "        dsig = np.multiply(self.activate(Z),(1-self.activate(Z)))\n",
    "        return dsig\n",
    "    \n",
    "class relu:\n",
    "    def activate(Z):\n",
    "        A = Z*(Z>0)\n",
    "        return A\n",
    "    \n",
    "    def diff(self,Z):\n",
    "        d_rel = 1*(Z>0)\n",
    "        return d_rel\n",
    "    \n",
    "# wrong implementation of leaky\n",
    "class leaky_relu:\n",
    "    def activate(Z):\n",
    "        A = Z if (Z.all()>0.001*Z.all()) else 0.001*Z\n",
    "        return A\n",
    "    \n",
    "    def diff(self,Z):\n",
    "        d_lrel = 1 if (Z.all()>0.001*Z.all()) else 0.001\n",
    "        return d_lrel\n",
    "    \n",
    "class tanh:\n",
    "    def activate(Z):\n",
    "        A = np.tanh(Z)\n",
    "        return A\n",
    "\n",
    "    def diff(self,Z):\n",
    "        d_tanh = 1 - (np.multiply(self.activate(Z),self.activate(Z)))\n",
    "        return d_tanh\n",
    "    \n",
    "class softmax:\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    def activate(Z):\n",
    "        e_Z = np.exp(Z- np.max(Z,axis=0))\n",
    "        return e_Z / e_Z.sum(axis=0)\n",
    "    \n",
    "    def diff(Z):\n",
    "        return Z\n",
    "    \n",
    "class CE_loss:\n",
    "    def get_loss(H,Y):\n",
    "        L = -np.mean(np.multiply(Y,np.log(H)))\n",
    "        return L\n",
    "    \n",
    "    def diff(H,Y):\n",
    "        dZ = H - Y \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializations taken from : https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Matrix\n",
    "def init_theta(n1,n2,activation):\n",
    "    #n1 = number of nodes in prev layer (input)\n",
    "    #n2 = number of nodes in next layer (output)\n",
    "    if activation in [sigmoid,softmax]:\n",
    "        M = np.random.randn(n2,n1)*np.sqrt(2./n1)\n",
    "    elif activation in [relu,leaky_relu] :\n",
    "        M = np.random.randn(n2,n1)*np.sqrt(1./n1)\n",
    "    elif activation == tanh:\n",
    "        M = np.random.randn(n2,n1)*np.sqrt(1./(n1+n2))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = read_idx('data/MNIST/train/train-images-idx3-ubyte')\n",
    "X = flatten_imgs(X)\n",
    "X = normalize(X)\n",
    "X = np.transpose(X)\n",
    "\n",
    "Y = read_idx('data/MNIST/train/train-labels-idx1-ubyte')\n",
    "Y = np.expand_dims(Y, axis=1)\n",
    "Y = np.transpose(Y)\n",
    "Y = one_hot(Y,10)\n",
    "\n",
    "X_test = read_idx('data/MNIST/test/t10k-images.idx3-ubyte')\n",
    "X_test = flatten_imgs(X_test)\n",
    "X_test = normalize(X_test)\n",
    "X_test = np.transpose(X_test)\n",
    "\n",
    "Y_test = read_idx('data/MNIST/test/t10k-labels.idx1-ubyte')\n",
    "Y_test = np.expand_dims(Y_test, axis=1)\n",
    "Y_test = np.transpose(Y_test)\n",
    "Y_test = one_hot(Y_test,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "plt.imshow(X[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(Y[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, n_prev, n_next, activation):\n",
    "        self.W = init_theta(n_prev, n_next, activation)\n",
    "        self.B = init_theta(1, n_next, activation)\n",
    "        self.activation = activation\n",
    "        self.V_dW = np.zeros(self.W.shape)\n",
    "        self.V_dB = np.zeros(self.B.shape)\n",
    "        \n",
    "    def forward(self, A0):\n",
    "        self.Z = np.dot(self.W, A0) + self.B\n",
    "        self.A = self.activation.activate(self.Z)\n",
    "        return self.A\n",
    "    \n",
    "    def grad(self, dZ, W, A0, m):\n",
    "        dA = np.dot(W.T, dZ)\n",
    "        dAdZ = self.activation.diff(self.activation, self.Z)\n",
    "        self.dZ = np.multiply(dA, dAdZ)\n",
    "        self.dW = (1./m)*np.dot(self.dZ, A0.T)\n",
    "        self.dB = (1./m)*(np.sum(self.dZ, axis=1, keepdims=True))\n",
    "    \n",
    "    def out_grad(self, dZ, A0, m):\n",
    "        self.dZ = dZ\n",
    "        self.dW = (1./m)*np.dot(self.dZ, A0.T)\n",
    "        self.dB = (1./m)*(np.sum(self.dZ, axis=1, keepdims=True))\n",
    "        \n",
    "    def step(self, lr, beta):\n",
    "        self.V_dW = (beta * self.V_dW + (1. - beta) * self.dW)\n",
    "        self.V_dB = (beta * self.V_dB + (1. - beta) * self.dB)\n",
    "        self.W = self.W - lr*self.V_dW\n",
    "        self.B = self.B - lr*self.V_dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_net:\n",
    "    def __init__(self, X_size, Y_size, lossfn):\n",
    "        self.L1 = layer(X_size, 500, relu)\n",
    "        self.L2 = layer(500, 150, relu)        \n",
    "        self.L3 = layer(150, Y_size, softmax)\n",
    "        self.lossfn = lossfn\n",
    "        \n",
    "    def f_pass(self, X):\n",
    "        A1 = self.L1.forward(X)\n",
    "        A2 = self.L2.forward(A1)\n",
    "        A3 = self.L3.forward(A2)\n",
    "        self.H = A3\n",
    "        return self.H\n",
    "    \n",
    "    def back_prop(self,X,Y, batch_size):\n",
    "        m = batch_size\n",
    "        self.loss = self.lossfn.get_loss(self.H,Y)\n",
    "        dZ = self.lossfn.diff(self.H,Y)\n",
    "        self.L3.out_grad(dZ, self.L2.A, m)\n",
    "        self.L2.grad(self.L3.dZ, self.L3.W, self.L1.A, m)\n",
    "        self.L1.grad(self.L2.dZ, self.L2.W, X, m)\n",
    "    \n",
    "    def optim(self, lr, beta=0):\n",
    "        self.L1.step(lr,beta)\n",
    "        self.L2.step(lr,beta)\n",
    "        self.L3.step(lr,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(batch_size,X,Y,model,lr,beta):\n",
    "    m = np.shape(X)[1]\n",
    "    for i in range(0,m,batch_size):\n",
    "        X_batch = X[:,i:i+batch_size]\n",
    "        Y_batch = Y[:,i:i+batch_size]\n",
    "        model.f_pass(X_batch)\n",
    "        model.back_prop(X_batch,Y_batch,batch_size)\n",
    "        model.optim(lr,beta)\n",
    "    return model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model creation\n",
    "n_in = np.shape(X)[0]\n",
    "n_out = np.shape(Y)[0]\n",
    "mnist_net = MNIST_net(n_in,n_out,CE_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 32\n",
    "lr = 0.075\n",
    "n_epochs = 10\n",
    "lr_decay = 0.9\n",
    "beta = 0.9\n",
    "data_size = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10/10 | Loss:0.0003 | Train Accuracy: 1.0000 | Test_Accuracy:0.9850\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for e in range(n_epochs):\n",
    "    #shuffle dataset\n",
    "    np.random.seed(138)\n",
    "    shuffle_index = np.random.permutation(data_size)\n",
    "    X, Y = X[:,shuffle_index], Y[:,shuffle_index]\n",
    "    \n",
    "    #SGD with momentum\n",
    "    loss = SGD(batch_size,X,Y,mnist_net,lr,beta)\n",
    "    \n",
    "    lr = lr*lr_decay\n",
    "    \n",
    "    H = mnist_net.f_pass(X)\n",
    "    O = inv_one_hot(H)\n",
    "    L = inv_one_hot(Y)\n",
    "    tr_acc = model_accuracy(O,L)\n",
    "    \n",
    "    H = mnist_net.f_pass(X_test)\n",
    "    O = inv_one_hot(H)\n",
    "    L = inv_one_hot(Y_test)\n",
    "    acc = model_accuracy(O,L)\n",
    "    \n",
    "    plt.plot(e,tr_acc, 'bo')\n",
    "    plt.plot(e,acc,'ro')\n",
    "    clear_output()\n",
    "    print(f\"epoch:{e+1}/{n_epochs} | Loss:{loss:.4f} | Train Accuracy: {tr_acc:.4f} | Test_Accuracy:{acc:.4f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlinepub",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
