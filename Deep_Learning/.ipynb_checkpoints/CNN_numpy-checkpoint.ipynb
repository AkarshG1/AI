{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from atlas_ml import *\n",
    "import pandas as pd\n",
    "import struct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(img_matrix, padding):\n",
    "    pad_width = [(0,0),(0,0),(padding[0],padding[0]),(padding[1],padding[1])]\n",
    "    padded_matrix = np.pad(img_matrix, pad_width=pad_width, mode='constant',)\n",
    "    return padded_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing zero_padding()\n",
    "\n",
    "A = np.arange(2*3*4*4).reshape(2,3,4,4)\n",
    "P = zero_padding(A,[2,2])\n",
    "\n",
    "#print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://stackoverflow.com/questions/30109068/implement-matlabs-im2col-sliding-in-python\n",
    "\n",
    "def im2col(imgs, kernel_size, stride):\n",
    "    # Parameters\n",
    "    F = kernel_size\n",
    "    batch_size, D,H,W = imgs.shape\n",
    "    col_extent = (W - F[1]) + 1\n",
    "    row_extent = (H - F[0]) + 1\n",
    "\n",
    "    # Get batch block indices\n",
    "    batch_idx = np.arange(batch_size)[:, None, None] * D * H * W\n",
    "    # Get Starting block indices\n",
    "    start_idx = np.arange(F[0])[None, :,None]*W + np.arange(F[1])\n",
    "    # Generate Depth indices\n",
    "    didx=H*W*np.arange(D)\n",
    "    start_idx=(didx[None, :, None]+start_idx.ravel()).reshape((-1,F[0],F[1]))\n",
    "\n",
    "    # Get offsetted indices across the height and width of input array\n",
    "    offset_idx = np.arange(row_extent)[None, :, None]*W + np.arange(col_extent)\n",
    "    \n",
    "    # Get all actual indices & index into input array for final output\n",
    "    act_idx = (batch_idx + \n",
    "        start_idx.ravel()[None, :, None] + \n",
    "        offset_idx[:,::stride[0],::stride[1]].ravel())\n",
    "\n",
    "    col_matrix = np.take (imgs, act_idx)\n",
    "    return col_matrix, act_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 28, 28)\n",
      "(5, 27, 676)\n",
      "(5, 3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Testing im2col()\n",
    "A = np.random.rand(5,3,28,28) # 3 Sample input array with 1 channel\n",
    "kernel_size = [3,3] # Sample blocksize (rows x columns)\n",
    "stride = [1,1]\n",
    "out, act_idx = im2col(A,kernel_size,stride)\n",
    "print(A.shape)\n",
    "print(out.shape)\n",
    "#print(act_idx.shape)\n",
    "dA1 = np.random.rand(*out.shape)\n",
    "dA2 = np.zeros(A.shape)\n",
    "#print(dA1)\n",
    "for i in range(dA2.shape[-1]):\n",
    "    dA2.ravel()[act_idx[:,:,i].ravel()] += dA1[:,:,i].ravel()\n",
    "print(dA2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_filters(K, D, kernel_size, activation):\n",
    "        W = init_matrix(D*kernel_size[0]*kernel_size[1],K,activation)\n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, n_prev, n_next, activation):\n",
    "        self.W = init_matrix(n_prev, n_next, activation)\n",
    "        self.B = init_matrix(1, n_next, activation)\n",
    "        self.activation = activation()\n",
    "        \n",
    "        self.V_dW = np.zeros(self.W.shape)\n",
    "        self.V_dB = np.zeros(self.B.shape)\n",
    "        \n",
    "    def forward(self, A0):\n",
    "        self.Z = np.einsum('ln,ml-> mn',self.W, A0) + self.B\n",
    "        self.A = self.activation.activate(self.Z)\n",
    "        return self.A\n",
    "    \n",
    "    def grad(self, dA, A0, m):\n",
    "        dAdZ = self.activation.diff(self.Z)\n",
    "        self.dZ = np.multiply(dA, dAdZ)\n",
    "        self.dW = (1./m)*np.einsum('mn,ml->ln',self.dZ, A0)\n",
    "        self.dB = (1./m)*(np.einsum('mn->n',self.dZ))\n",
    "        dA_prev = np.einsum('ln,mn->ml',self.W, self.dZ) \n",
    "        return dA_prev\n",
    "    \n",
    "    def out_grad(self, dZ, A0, m):\n",
    "        self.dZ = dZ\n",
    "        self.dW = (1./m)*np.einsum('mn,ml->ln',self.dZ, A0)\n",
    "        self.dB = (1./m)*(np.einsum('mn->n',self.dZ))\n",
    "        dA_prev = np.einsum('ln,mn->ml',self.W, self.dZ) \n",
    "        return dA_prev\n",
    "        \n",
    "    def step(self, lr, beta):\n",
    "        self.V_dW = (beta * self.V_dW + (1. - beta) * self.dW)\n",
    "        self.V_dB = (beta * self.V_dB + (1. - beta) * self.dB)\n",
    "        self.W = self.W - lr*self.V_dW\n",
    "        self.B = self.B - lr*self.V_dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_layer:\n",
    "    def __init__(self, kernel_size, n_channels, activation, n_filters = 1, stride =[1,1],  padding = [0,0]):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_filters = n_filters\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.activation = activation()\n",
    "        \n",
    "        #intialize [n_filters,n_channels,kernel_size[0],kernel_size[1]] filters\n",
    "        self.W = init_filters(self.n_filters, self.n_channels, self.kernel_size, activation)\n",
    "        self.B = init_matrix( 1, n_filters, activation)\n",
    "        \n",
    "        self.V_dW = np.zeros(self.W.shape)\n",
    "        self.V_dB = np.zeros(self.B.shape)\n",
    "        \n",
    "    def get_output_shape(self, A_prev_shape):\n",
    "        batch_size,D,W,H = A_prev_shape\n",
    "        H_out = (H - self.kernel_size[0])//self.stride[0] + 1\n",
    "        W_out = (W - self.kernel_size[1])//self.stride[1] + 1\n",
    "        output_shape = (batch_size, self.n_filters, H_out, W_out)\n",
    "        return output_shape\n",
    "    \n",
    "    def forward(self, A_prev):\n",
    "        A_prev = zero_padding(A_prev, self.padding)        \n",
    "        self.A_prev_shape = A_prev.shape\n",
    "        self.im2cols, self.act_idx = im2col(A_prev,self.kernel_size, self.stride)\n",
    "        output_shape = self.get_output_shape(A_prev.shape)\n",
    "        \n",
    "        self.Z = np.einsum('mfn,fk->mnk',self.im2cols,self.W) + self.B   \n",
    "        self.A = self.activation.activate(self.Z)\n",
    "        self.A = np.transpose(self.A,(0,2,1)).reshape(output_shape)\n",
    "        return self.A\n",
    "    \n",
    "    def grad(self, dA):\n",
    "        batch_size = dA.shape[0]\n",
    "        dAdZ = self.activation.diff(self.Z)\n",
    "        self.dZ = np.einsum('mjk,mjk->mjk', dA, dAdZ)\n",
    "        \n",
    "        self.dW = (1./batch_size)*np.einsum('mjk,mkl->jl', self.im2cols, self.dZ)\n",
    "        self.dB = (1./batch_size)*np.einsum('mjk->k', self.dZ)\n",
    "        \n",
    "        dA_prev_cols = np.einsum('mnk,fk-> mfn',self.dZ, self.W) \n",
    "\n",
    "        dA_prev = np.zeros(self.A_prev_shape)        \n",
    "        for i in range(self.act_idx.shape[-1]):\n",
    "            dA_prev.ravel()[self.act_idx[:,:,i].ravel()] += dA_prev_cols[:,:,i].ravel()\n",
    "\n",
    "        dA_prev = dA_prev.reshape(dA_prev.shape[0],dA_prev.shape[1],dA_prev.shape[2]*dA_prev.shape[3])\n",
    "        dA_prev = np.transpose(dA_prev,(0,2,1))\n",
    "        \n",
    "        return dA_prev\n",
    "    \n",
    "    def step(self, lr, beta, reg_lambda=0):\n",
    "        self.V_dW = (beta * self.V_dW + (1. - beta) * self.dW)\n",
    "        self.V_dB = (beta * self.V_dB + (1. - beta) * self.dB)\n",
    "        self.W    =  self.W - lr*self.V_dW\n",
    "        self.B    =  self.B - lr*self.V_dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_CNN:\n",
    "    def __init__(self, Y_size, lossfn, n_channels=1):\n",
    "        self.L1 = conv_layer([5,5], n_channels, leaky_relu, n_filters = 10,padding = [2,2])\n",
    "        self.L2 = conv_layer([3,3], 10, leaky_relu, n_filters = 15)\n",
    "        self.L3 = max_pool_layer([2,2],15, stride=[2,2])\n",
    "        self.L4 = conv_layer([3,3], 15, leaky_relu)        \n",
    "        self.L5 = layer(121,50, leaky_relu)\n",
    "        self.L6 = layer(50, Y_size, softmax)\n",
    "        self.lossfn = lossfn()\n",
    "        \n",
    "    def f_pass(self, X):\n",
    "        A = self.L1.forward(X)\n",
    "        A = self.L2.forward(A)\n",
    "        A = self.L3.forward(A)\n",
    "        A = self.L4.forward(A)\n",
    "        A.resize(A.shape[0], A.shape[2]*A.shape[3])\n",
    "        A = self.L5.forward(A)\n",
    "        A = self.L6.forward(A)\n",
    "        self.H = A\n",
    "        return self.H\n",
    "    \n",
    "    def back_prop(self,X,Y, batch_size,reg_lambda=0):\n",
    "        m = batch_size\n",
    "        self.loss = self.lossfn.get_loss(self.H,Y)\n",
    "        dZ = self.lossfn.diff(self.H,Y)\n",
    "        dA = self.L6.out_grad(dZ, self.L5.A, m)\n",
    "        dA = self.L5.grad(dA,self.L4.A, m)\n",
    "        dA = np.expand_dims(dA,axis=-1)\n",
    "        dA = self.L4.grad(dA)\n",
    "        dA = self.L3.grad(dA)\n",
    "        dA = self.L2.grad(dA)\n",
    "        dX = self.L1.grad(dA)\n",
    "    \n",
    "    def optim(self, lr, beta=0):\n",
    "        self.L1.step(lr,beta)\n",
    "        self.L2.step(lr,beta)\n",
    "        self.L3.step(lr,beta)\n",
    "        self.L4.step(lr,beta)\n",
    "        self.L5.step(lr,beta)\n",
    "        self.L6.step(lr,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class max_pool_layer():\n",
    "    def __init__(self, kernel_size, n_channels, stride =[1,1],  padding = [0,0]):\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_channels = n_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "    def get_output_shape(self, A_prev_shape):\n",
    "        batch_size,D,W,H = A_prev_shape\n",
    "        H_out = (H - self.kernel_size[0])//self.stride[0] + 1\n",
    "        W_out = (W - self.kernel_size[1])//self.stride[1] + 1\n",
    "        output_shape = (batch_size, self.n_channels, H_out, W_out)\n",
    "        return output_shape\n",
    "    \n",
    "    def forward(self, A_prev):\n",
    "\n",
    "        A_prev = zero_padding(A_prev, self.padding)\n",
    "        self.A_prev_shape = A_prev.shape\n",
    "        self.im2cols, self.act_idx = im2col(A_prev, self.kernel_size, self.stride)\n",
    "        \n",
    "        output_shape = self.get_output_shape(A_prev.shape)\n",
    "        \n",
    "        self.Z = np.split(self.im2cols,self.n_channels,axis=1)\n",
    "        self.Z = np.stack(self.Z, axis=1)\n",
    "\n",
    "        self.A = np.max(self.Z,axis=2)  \n",
    "        self.arg = np.argmax(self.A,axis=2)\n",
    "        \n",
    "        self.A = self.A.reshape(output_shape)\n",
    "        return self.A\n",
    "    \n",
    "    def grad(self, dA):\n",
    "        batch_size = dA.shape[0]\n",
    "        dA = np.expand_dims(dA.transpose(0,2,1), axis=2)\n",
    "        A = self.A.reshape(self.A.shape[0],self.A.shape[1],1,self.A.shape[-2]*self.A.shape[-1])\n",
    "        dAdZ = (self.Z - A)==0\n",
    "        self.dZ = np.multiply(dA, dAdZ) \n",
    "        shape = self.dZ.shape\n",
    "        self.dZ = self.dZ.reshape(shape[0],shape[1]*shape[2],shape[3])\n",
    "        \n",
    "        dA_prev = np.zeros(self.A_prev_shape)        \n",
    "        \n",
    "        for i in range(self.act_idx.shape[-1]):\n",
    "            dA_prev.ravel()[self.act_idx[:,:,i].ravel()] += self.dZ[:,:,i].ravel()\n",
    "\n",
    "        dA_prev = dA_prev.reshape(dA_prev.shape[0],dA_prev.shape[1],dA_prev.shape[2]*dA_prev.shape[3])\n",
    "        dA_prev = np.transpose(dA_prev,(0,2,1))\n",
    "        \n",
    "        return dA_prev\n",
    "    \n",
    "    def step(self, lr, beta, reg_lambda=0):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(batch_size,X,Y,model,lr,beta,reg_lambda=0):\n",
    "    m = np.shape(X)[0]\n",
    "    H = np.zeros(Y.shape)\n",
    "    for i in range(0,m,batch_size):\n",
    "        X_batch = X[i:i+batch_size]\n",
    "        Y_batch = Y[i:i+batch_size]\n",
    "        H[i:i+batch_size] = model.f_pass(X_batch)\n",
    "        model.back_prop(X_batch, Y_batch, batch_size, reg_lambda)\n",
    "        model.optim(lr,beta) \n",
    "    O = inv_one_hot(H)\n",
    "    L = inv_one_hot(Y)\n",
    "    tr_acc = model_accuracy(O,L)    \n",
    "    return model.loss, tr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_path = 'MNIST_np/data/MNIST/train/train-images-idx3-ubyte'\n",
    "trainY_path = 'MNIST_np/data/MNIST/train/train-labels-idx1-ubyte'\n",
    "testX_path  = 'MNIST_np/data/MNIST/test/t10k-images.idx3-ubyte'\n",
    "testY_path  = 'MNIST_np/data/MNIST/test/t10k-labels.idx1-ubyte'\n",
    "\n",
    "X,Y,X_test,Y_test = load_mnist_data(trainX_path,trainY_path,testX_path,testY_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = np.shape(Y)[1]\n",
    "mnist_net = MNIST_CNN(n_out,CE_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "lr = 0.0004\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "lr_decay = 0.9\n",
    "\n",
    "data_size = X.shape[0]\n",
    "\n",
    "beta = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.20115433e-177, 1.00000000e+000, 7.14746198e-298,\n",
       "        8.76894688e-178, 2.49832063e-146, 3.04895646e-143,\n",
       "        4.21460700e-264, 5.47036439e-269, 2.50293083e-228,\n",
       "        0.00000000e+000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net.f_pass(X[12:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.173987435535112"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time. time()\n",
    "mnist_net.f_pass(X[0:4])\n",
    "endf = time. time()\n",
    "mnist_net.back_prop(X[0:4],Y[0:4],4)\n",
    "endb = time. time()\n",
    "mnist_net.optim(lr,beta)\n",
    "endo = time. time()\n",
    "mnist_net.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-21"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.975921313417553"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net.L6.dW.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-pass:0.0171 | b-prop:0.0191 | optim: 0.0003 | total: 0.0364\n"
     ]
    }
   ],
   "source": [
    "print(f\"f-pass:{endf-start:.4f} | b-prop:{endb-endf:.4f} | optim: {endo-endb:.4f} | total: {endo-start:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 1. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      "  5. 1. 5. 5. 1. 5. 5. 5. 5. 5. 5. 5. 5. 3. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      "  5. 5. 5. 3. 5. 5. 5. 5. 3. 5. 5. 5. 5. 5. 5. 3.]]\n",
      "[[5. 0. 4. 1. 9. 2. 1. 3. 1. 4. 3. 5. 3. 6. 1. 7. 2. 8. 6. 9. 4. 0. 9. 1.\n",
      "  1. 2. 4. 3. 2. 7. 3. 8. 6. 9. 0. 5. 6. 0. 7. 6. 1. 8. 7. 9. 3. 9. 8. 5.\n",
      "  9. 3. 3. 0. 7. 4. 9. 8. 0. 9. 4. 1. 4. 4. 6. 0.]]\n"
     ]
    }
   ],
   "source": [
    "H = mnist_net.f_pass(X[0:64])\n",
    "O = inv_one_hot(H)\n",
    "L = inv_one_hot(Y[0:64])\n",
    "print(O.T)\n",
    "print(L.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1/20 | Loss:1.1917 Train Accuracy: 0.1336 | Test_Accuracy:0.1525\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-47ac5a52ec1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train(mnist_net, X, Y, X_test, Y_test, model_accuracy, n_epochs, \\\n\u001b[0;32m----> 2\u001b[0;31m     batch_size, lr, lr_decay, beta, reg_lambda=0)\n\u001b[0m",
      "\u001b[0;32m~/Projects/AI/Deep_Learning/atlas_ml.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X, Y, X_test, Y_test, metric, n_epochs, batch_size, lr, lr_decay, beta, reg_lambda)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;31m#SGD with momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AI/Deep_Learning/atlas_ml.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(batch_size, X, Y, model, lr, beta, reg_lambda)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-da2d9fc77d5d>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(self, X, Y, batch_size, reg_lambda)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mdX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ee634c2ec3f7>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self, dA)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mjk,mjk->mjk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdAdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mjk,mkl->jl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim2cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mjk->k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/onlinepub/lib/python3.6/site-packages/numpy/core/einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*operands, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;31m# If no optimization, run pure einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimize_arg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m     \u001b[0mvalid_einsum_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'casting'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(mnist_net, X, Y, X_test, Y_test, model_accuracy, n_epochs, \\\n",
    "    batch_size, lr, lr_decay, beta, reg_lambda=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(n_epochs):\n",
    "    #shuffle dataset\n",
    "    np.random.seed(138)\n",
    "    shuffle_index = np.random.permutation(data_size)\n",
    "    X, Y = X[shuffle_index,:], Y[shuffle_index,:]\n",
    "    \n",
    "    #SGD with momentum\n",
    "    loss, tr_acc = SGD(batch_size,X,Y,mnist_net,lr,beta)\n",
    "    lr = lr*lr_decay\n",
    "    \n",
    "    m = np.shape(X_test)[0]\n",
    "    H = np.zeros(Y_test.shape)\n",
    "    for i in range(0,m,batch_size):\n",
    "        X_test_batch = X_test[i:i+batch_size]\n",
    "        H[i:i+batch_size] = mnist_net.f_pass(X_test_batch)\n",
    "    O = inv_one_hot(H)\n",
    "    L = inv_one_hot(Y_test)\n",
    "    acc = model_accuracy(O,L)\n",
    "    \n",
    "    plt.plot(e,tr_acc, 'bo')\n",
    "    plt.plot(e,acc,'ro')\n",
    "    clear_output()\n",
    "    print(f\"epoch:{e+1}/{n_epochs} | Loss:{loss:.4f} | Train Accuracy: {tr_acc:.4f} | Test_Accuracy:{acc:.4f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(model, output, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    model = None\n",
    "    with open(filename, 'r') as f:  # Overwrites any existing file.\n",
    "        model = pickle.load(f)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(mnist_net,\"mnist_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(\"mnist_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlinepub",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
